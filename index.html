<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yiming Dou</title>

  <meta name="author" content="Yiming Dou">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <!-- Bio -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Yiming Dou Á™¶Èì±Êòé</name>
                  </p>
                  <!-- bio -->
                  <p style="text-align:justify">
                    Hi! I'm a senior student from <strong>Shanghai Jiao Tong University (SJTU)</strong>.
                    Currently, I'm working with <a href="https://ai.stanford.edu/~rhgao/">Dr. Ruohan Gao</a> as a
                    research
                    intern at <strong>Stanford University</strong>, supervised by <strong><a
                        href="https://jiajunwu.com/">Prof. Jiajun Wu</a></strong>.
                    I also work with <a href="https://dirtyharrylyl.github.io/">Prof. Yong-Lu Li</a> as an undergraduate
                    researcher at SJTU, supervised by <strong><a href="https://www.mvig.org/">Prof. Cewu Lu</a></strong>.
                    My research interests mainly lie in <strong>computer vision</strong>, <strong>multimodal</strong>
                    and <strong>robotics</strong>.
                  </p>
                  <p>
                    I'm always happy to make friends with people from various backgrounds. Feel free to contact my WeChat: 18017112986.
                  </p>
                  <p>
                    I'm actively applying for a Ph.D. position in 2023 Fall!
                  </p>

                  <!-- links -->
                  <p style="text-align:center">
                    <a href="mailto:yiming.dou.1@gmail.com">Email</a> &nbsp¬∑&nbsp
                    <!-- <a href="files/CV_Yiming Dou.pdf">CV</a> &nbsp/&nbsp -->
                    <a href="https://scholar.google.com/citations?user=IMsjP1sAAAAJ">Google Scholar</a> &nbsp¬∑&nbsp
                    <a href="https://twitter.com/_YimingDou">Twitter</a> &nbsp¬∑&nbsp
                    <a href="https://github.com/Dou-Yiming">Github</a>
                  </p>
                </td>
                <!-- profile image -->
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="figs/profile_new.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="figs/profile_new.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <!-- News -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 20px;width:100%;vertical-align:middle">
                  <heading>News</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="padding:0%;width:96%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 10px;width:100%;vertical-align:middle">
                  <p>
                    <li>
                      02/2023: 
                      &#x1F389;
                      Our paper "The ObjectFolder Benchmark: Multisensory Learning 
                      with Neural and Real Objects" is accepted by CVPR 2023.
                    </li>
                  </p>
                </td>
              </tr>

            </tbody>
          </table>
          
          <!-- Research Interests -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 20px;width:100%;vertical-align:middle">
                  <heading>Research Interests</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="padding:0%;width:96%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 10px;width:100%;vertical-align:middle;text-align:justify"">
                  <p style="text-align:justify">
                    Humans perceive the world with multiple senses,
                    based on which we establish abstract concepts to understand it.
                    From the concepts we develop logical reasoning ability, 
                    and thus creating brilliant achievements.
                    Inspired by the fascinating human intelligence, 
                    my dream is to design human-like intelligent systems, 
                    which can be divided into four specific problems:
                    <li style="line-height:125%">
                      <strong>Multimodal Perception</strong>: 
                      how to effectively incorporate multiple modalities 
                      (e.g., vision, touch, audio, language and even smell or taste) 
                      into AI systems to make them extract 
                      as much information from the surrounding world as possible.
                    </li>
                    <li style="line-height:125%">
                      <strong>Concept Learning</strong>: 
                      how to abstract and summarize the perceived information into high-level concepts 
                      (e.g., languages or symbols), 
                      thus enabling generalizable cross-domain understanding.
                    </li>
                    <li style="line-height:125%">
                      <strong>Reasoning</strong>: 
                      how to extract relations from complex scenes 
                      and perform causal reasoning on the basis of concepts.
                    </li>
                    <li style="line-height:125%">
                      <strong>Robot Learning</strong>: 
                      how to enable agents/robots to interact with the real-world environments and humans 
                      by leveraging the intelligence learnt from the former three stages.
                    </li>
                  </p>
                </td>
              </tr>

            </tbody>
          </table>
          <!-- Publications -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 20px;width:100%;vertical-align:middle">
                  <heading>Publications</heading>
                  <p>(* indicates equal contribution)</p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr>
                <td style="padding:10px 20px;width:25%;vertical-align:middle" align="center">
                  <img src="figs/publications/objectfolder_benchmark.png" style="border-style: none" height="150">
                </td>
                <td width="75%" valign="middle">
                  <!-- heading -->
                  <papertitle>The ObjectFolder Benchmark: Multisensory Learning with Neural and Real
                    Objects</papertitle>
                  <!-- authors -->
                  <br>
                  Ruohan Gao*,
                  <strong>Yiming Dou</strong>*,
                  Hao Li*,
                  Tanmay Agarwal,
                  Jeannette Bohg,
                  Yunzhu Li,
                  Li Fei-Fei,
                  Jiajun Wu
                  <!-- conference & date -->
                  <br>
                  Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2023
                  <br>
                  <!-- links -->
                  arXiv
                  / <a href="https://objectfolder.stanford.edu/">Project Page</a>
                  / <a href="https://www.objectfolder.org/swan_vis/">Interactive Demo</a>
                  <!-- / <a href="TBD">arXiv</a> -->
                </td>
              </tr>

              <tr>
                <td style="padding:10px 20px;width:25%;vertical-align:middle" align="center">
                  <img src="figs/publications/pangea.png" style="border-style: none" height="150">
                </td>
                <td width="75%" valign="middle">
                  <!-- heading -->
                  <papertitle>Bridging The Isolated Islands in Human Action Understanding</papertitle>
                  <!-- authors -->
                  <br>
                  Yong-Lu Li*,
                  Xiaoqian Wu*,
                  Xinpeng Liu,
                  <strong>Yiming Dou</strong>,
                  Yikun Ji,
                  Junyi Zhang,
                  Yixing Li,
                  Xudong Lu,
                  Jingru Tan,
                  Cewu Lu
                  <!-- conference & date -->
                  <br>
                  <em>Under review</em>, 2022
                  <br>
                  <!-- links -->
                  arXiv
                  / <a href="https://github.com/DirtyHarryLYL/Sandwich">Project Page</a>
                  <!-- / <a href="TBD">arXiv</a> -->
                </td>
              </tr>

              <tr>
                <td style="padding:10px 20px;width:25%;vertical-align:middle" align="center">
                  <img src="figs/publications/resu.png" style="border-style: none" height="150">
                </td>
                <td width="75%" valign="middle">
                  <!-- heading -->
                  <papertitle>ReSU: A Novel Interactive-Action Driven Benchmark for Embodied Visual Grounding
                  </papertitle>
                  <!-- authors -->
                  <br>
                  <strong>Yiming Dou</strong>*,
                  Yong-Lu Li*,
                  Cewu Lu
                  <!-- conference & date -->
                  <br>
                  <em>Under review</em>, 2022
                  <br>
                  <!-- links -->
                  arXiv
                  <!-- / <a href="TBD">arXiv</a> -->
                </td>
              </tr>

              <tr>
                <td style="padding:10px 20px;width:25%;vertical-align:middle" align="center">
                  <img src="figs/publications/dio.png" style="border-style: none" height="150">
                </td>
                <td width="75%" valign="middle">
                  <!-- heading -->
                  <papertitle>Discovering A Variety of Objects in Spatio-Temporal Human-Object Interactions</papertitle>
                  <!-- authors -->
                  <br>
                  Yong-Lu Li*,
                  Hongwei Fan*,
                  Zuoyu Qiu,
                  <strong>Yiming Dou</strong>,
                  Liang Xu,
                  Hao-Shu Fang,
                  Peiyang Guo,
                  Haisheng Su,
                  Dongliang Wang,
                  Wei Wu,
                  Cewu Lu
                  <!-- conference & date -->
                  <br>
                  Technical report, 2022
                  <br>
                  <!-- links -->
                  <a href="https://arxiv.org/abs/2211.07501">arXiv</a>
                  / <a href="https://github.com/DirtyHarryLYL/HAKE-AVA">Project Page</a>
                </td>
              </tr>

            </tbody>
          </table>
          <!-- Service -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 20px;width:100%;vertical-align:middle">
                  <heading>Service</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="padding:0%;width:96%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 10px;width:100%;vertical-align:middle">
                  <p>
                    <li style="line-height:125%">
                      Reviewer for CVPR 2023 Workshop on 3D Vision and Robotics
                    </li>
                    </li>
                  </p>
                </td>
              </tr>

            </tbody>
          </table>
          <!-- Experience -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 20px;width:100%;vertical-align:middle">
                  <heading>Experience</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr>
                <td style="padding:10px 50px;width:25%;vertical-align:middle" align="center">
                  <img src="figs/Stanford_logo.png" style="border-style: none" height="100">
                </td>

                <td width="75%" valign="middle">
                  <!-- heading -->
                  <university>Stanford University</university>
                  <br>
                  2022.03 ~ present
                  <br>
                  California, U.S.A.
                  <br>
                  Visiting Research Intern
                  <br>
                  Supervisor: Prof. Jiajun Wu
                  <!-- conference & date -->
                </td>
              </tr>

              <tr>
                <td style="padding:10px 50px;width:25%;vertical-align:middle" align="center">
                  <img src="figs/SJTU_logo.png" style="border-style: none" height="100">
                </td>

                <td width="75%" valign="middle">
                  <!-- heading -->
                  <university>Shanghai Jiao Tong University</university>
                  <br>
                  2019.09 ~ present
                  <br>
                  Shanghai, China
                  <br>
                  B.Eng. in Computer Science and Technology (Honor), <a href="https://en.zhiyuan.sjtu.edu.cn/">Zhiyuan
                    Honors Program</a>
                  <br>
                  B.Ec. in Economics (Associate Degree)
                  <br>
                  Supervisor: Prof. Cewu Lu and Prof. Yong-Lu Li
                  <!-- conference & date -->
                </td>
              </tr>

            </tbody>
          </table>
          <!-- Honors -->
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 20px;width:100%;vertical-align:middle">
                  <heading>Honors</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="padding:0%;width:96%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px 10px;width:100%;vertical-align:middle">
                  <p>
                    <li style="line-height:125%">
                      <honor>SJTU Overseas Scholarship</honor> (two winners in SJTU), SJTU, 2022
                    </li>
                    <li style="line-height:125%">
                      <honor>Academic Excellence Scholarship</honor> (top 10%), SJTU, 2022
                    </li>
                    <li style="line-height:125%">
                      <honor>Zhanjiajun Scholarship</honor> (six winners in SJTU), SJTU, 2022
                    </li>
                    <li style="line-height:125%">
                      <honor><a href="files/MCM2022/2208999.pdf">Meritorious Winner</a></honor> (top 7%), MCM, 2022
                    </li>
                    <li style="line-height:125%">
                      <honor><a href="files/Honors/Merit-Student-2021.jpg">Merit Student Award</a></honor> (top 5%), SJTU, 2021
                    </li>
                    <li style="line-height:125%">
                      <honor><a href="files/Scholarship/Zhiyuan-Honors-Scholarship-2020.jpg">Zhiyuan Honors Scholarship</a>
                      </honor> (top 5%), SJTU, 2019, 2020, 2021, 2022
                    </li>
                  </p>
                </td>
              </tr>

            </tbody>
          </table>
        </td>
      </tr>
      <tr style="padding:200px">
        <script type='text/javascript' id='clustrmaps'
          src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=9RqQ_Wyrwtnc77JFqXfEZmLqhMIuy42lE14nZdXa6Sk'></script>
      </tr>
  </table>
  <p style="text-align:right;font-size:small;">
    <a href="https://github.com/jonbarron/jonbarron_website">Template from Jon Barron's website</a>
  </p>
</body>

</html>